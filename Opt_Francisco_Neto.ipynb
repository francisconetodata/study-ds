{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 91717,
          "databundleVersionId": 12184666,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31040,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Opt - Francisco Neto",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "1Ht4Tpew6C2H"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "playground_series_s5e6_path = kagglehub.competition_download('playground-series-s5e6')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "Z0tgj4Yb6C2I"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-27T02:27:21.635601Z",
          "iopub.execute_input": "2025-06-27T02:27:21.636097Z",
          "iopub.status.idle": "2025-06-27T02:27:24.367967Z",
          "shell.execute_reply.started": "2025-06-27T02:27:21.636067Z",
          "shell.execute_reply": "2025-06-27T02:27:24.366778Z"
        },
        "id": "TLGKp0zU6C2J"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 1. IMPORTAÇÃO DAS BIBLIOTECAS NECESSÁRIAS\n",
        "# ==============================================================================\n",
        "# Importando as ferramentas essenciais para manipulação de dados,\n",
        "# modelagem e visualização.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.metrics import top_k_accuracy_score # Usaremos para validação local\n",
        "import warnings\n",
        "\n",
        "# Ignorar warnings para manter a saída limpa\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Bibliotecas importadas com sucesso!\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. CARREGAMENTO DOS DADOS (VERSÃO CORRIGIDA)\n",
        "# ==============================================================================\n",
        "# A competição nos incentiva a usar o dataset original. Vamos fazer isso!\n",
        "# Carregaremos os dados sintéticos da competição e o dataset real,\n",
        "# e depois os combinaremos para ter um conjunto de treinamento mais robusto.\n",
        "\n",
        "BASE_PATH = '/kaggle/input/playground-series-s5e6/'\n",
        "try:\n",
        "    original_df = pd.read_csv('/kaggle/input/fertilizer-prediction/Fertilizer Prediction.csv')\n",
        "    # Renomeando colunas do dataset original para bater com o da competição\n",
        "    original_df.rename(columns={\n",
        "        'Temparature': 'Temperature', # Corrigindo erro de digitação\n",
        "        'Humidity ': 'Humidity',\n",
        "        'Moisture': 'Moisture',\n",
        "        'Soil Type': 'Soil_Type',\n",
        "        'Crop Type': 'Crop_Type',\n",
        "        'Nitrogen': 'Nitrogen',\n",
        "        'Potassium': 'Potassium',\n",
        "        'Phosphorous': 'Phosphorous',\n",
        "        'Fertilizer Name': 'Fertilizer_Name'\n",
        "    }, inplace=True)\n",
        "    print(\"Dataset original carregado com sucesso.\")\n",
        "    USE_ORIGINAL_DATA = True\n",
        "except FileNotFoundError:\n",
        "    print(\"Dataset original não encontrado. Prosseguindo apenas com os dados da competição.\")\n",
        "    USE_ORIGINAL_DATA = False\n",
        "\n",
        "\n",
        "# Carregando os dados da competição\n",
        "train_df = pd.read_csv(BASE_PATH + 'train.csv')\n",
        "test_df = pd.read_csv(BASE_PATH + 'test.csv')\n",
        "sample_submission_df = pd.read_csv(BASE_PATH + 'sample_submission.csv')\n",
        "\n",
        "# ==============================================================================\n",
        "# CORREÇÃO: Padronizando o nome da coluna 'Temparature' imediatamente\n",
        "# ==============================================================================\n",
        "# Esta é a correção chave para o KeyError que você encontrou.\n",
        "rename_dict = {'Temparature': 'Temperature'}\n",
        "train_df.rename(columns=rename_dict, inplace=True)\n",
        "test_df.rename(columns=rename_dict, inplace=True)\n",
        "print(\"\\nColuna 'Temparature' corrigida para 'Temperature' nos dataframes da competição.\")\n",
        "# ==============================================================================\n",
        "\n",
        "# Guardando os IDs do teste para a submissão final\n",
        "test_ids = test_df['id']\n",
        "# Removendo a coluna 'id' para que os dataframes de treino e teste tenham as mesmas colunas\n",
        "train_df = train_df.drop('id', axis=1)\n",
        "test_df = test_df.drop('id', axis=1)\n",
        "\n",
        "print(\"\\nDados da competição carregados:\")\n",
        "print(f\"Treino: {train_df.shape}\")\n",
        "print(f\"Teste: {test_df.shape}\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. PRÉ-PROCESSAMENTO E ENGENHARIA DE FEATURES (VERSÃO CORRIGIDA)\n",
        "# ==============================================================================\n",
        "# Esta etapa agora funcionará sem erros, pois o nome da coluna já foi corrigido.\n",
        "\n",
        "# --- 3.1. Limpeza e Unificação dos Nomes das Colunas ---\n",
        "# Padronizar os nomes das colunas (trocar espaços por _) ajuda a evitar erros.\n",
        "def clean_col_names(df):\n",
        "    cols = df.columns\n",
        "    new_cols = []\n",
        "    for col in cols:\n",
        "        # Garante que não haja espaços no início/fim e substitui espaços internos\n",
        "        clean_col = col.strip().replace(' ', '_')\n",
        "        new_cols.append(clean_col)\n",
        "    df.columns = new_cols\n",
        "    return df\n",
        "\n",
        "train_df = clean_col_names(train_df)\n",
        "test_df = clean_col_names(test_df)\n",
        "if USE_ORIGINAL_DATA:\n",
        "    original_df = clean_col_names(original_df)\n",
        "\n",
        "\n",
        "# --- 3.2. Combinando com o Dataset Original (se disponível) ---\n",
        "if USE_ORIGINAL_DATA:\n",
        "    # Unindo o dataset original ao de treino\n",
        "    train_df = pd.concat([train_df, original_df[train_df.columns]], ignore_index=True)\n",
        "    print(f\"\\nFormato do treino após combinar com dados originais: {train_df.shape}\")\n",
        "\n",
        "\n",
        "# --- 3.3. Engenharia de Features (\"A Parte Legal\") ---\n",
        "# A função agora encontrará a coluna 'Temperature' sem problemas.\n",
        "print(\"\\nIniciando Engenharia de Features...\")\n",
        "\n",
        "def create_features(df):\n",
        "    df_copy = df.copy()\n",
        "    epsilon = 1e-6\n",
        "\n",
        "    # Relações entre nutrientes (N-P-K)\n",
        "    df_copy['N_P_Ratio'] = df_copy['Nitrogen'] / (df_copy['Phosphorous'] + epsilon)\n",
        "    df_copy['N_K_Ratio'] = df_copy['Nitrogen'] / (df_copy['Potassium'] + epsilon)\n",
        "    df_copy['P_K_Ratio'] = df_copy['Phosphorous'] / (df_copy['Potassium'] + epsilon)\n",
        "    df_copy['N_P_K_Sum'] = df_copy['Nitrogen'] + df_copy['Phosphorous'] + df_copy['Potassium']\n",
        "\n",
        "    # Interação entre clima e umidade do solo\n",
        "    # AGORA ISSO FUNCIONARÁ\n",
        "    df_copy['Temp_Humidity_Interaction'] = df_copy['Temperature'] * df_copy['Humidity']\n",
        "    df_copy['Temp_Moisture_Interaction'] = df_copy['Temperature'] * df_copy['Moisture']\n",
        "\n",
        "    return df_copy\n",
        "\n",
        "train_df = create_features(train_df)\n",
        "test_df = create_features(test_df)\n",
        "print(train_df.info())\n",
        "print(test_df.info())\n",
        "\n",
        "print(\"Novas features criadas com sucesso!\")\n",
        "print(\"Novas colunas:\", [col for col in train_df.columns if col not in test_df.columns and col != 'Fertilizer_Name'])\n",
        "\n",
        "\n",
        "# --- 3.4. Codificação da Variável Alvo (Target Encoding) ---\n",
        "target_encoder = LabelEncoder()\n",
        "train_df['Fertilizer_Name_Encoded'] = target_encoder.fit_transform(train_df['Fertilizer_Name'])\n",
        "fertilizer_classes = target_encoder.classes_\n",
        "print(f\"\\nEncontrados {len(fertilizer_classes)} tipos de fertilizantes.\")\n",
        "\n",
        "\n",
        "# --- 3.5. Codificação das Features Categóricas (One-Hot Encoding) ---\n",
        "categorical_features = ['Soil_Type', 'Crop_Type']\n",
        "combined_df = pd.concat([train_df.drop(['Fertilizer_Name', 'Fertilizer_Name_Encoded'], axis=1), test_df], ignore_index=True)\n",
        "combined_df = pd.get_dummies(combined_df, columns=categorical_features, drop_first=True)\n",
        "\n",
        "X = combined_df[:len(train_df)]\n",
        "X_test = combined_df[len(train_df):]\n",
        "y = train_df['Fertilizer_Name_Encoded']\n",
        "\n",
        "print(\"\\nPré-processamento finalizado.\")\n",
        "print(f\"Formato final do dataset de treino (features): {X.shape}\")\n",
        "print(f\"Formato final do dataset de teste (features): {X_test.shape}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-27T02:32:56.835743Z",
          "iopub.execute_input": "2025-06-27T02:32:56.836127Z",
          "iopub.status.idle": "2025-06-27T02:32:58.58313Z",
          "shell.execute_reply.started": "2025-06-27T02:32:56.836102Z",
          "shell.execute_reply": "2025-06-27T02:32:58.582102Z"
        },
        "id": "HtTooWX16C2J"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_df"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-27T02:31:00.048045Z",
          "iopub.execute_input": "2025-06-27T02:31:00.048422Z",
          "iopub.status.idle": "2025-06-27T02:31:00.077213Z",
          "shell.execute_reply.started": "2025-06-27T02:31:00.048396Z",
          "shell.execute_reply": "2025-06-27T02:31:00.076138Z"
        },
        "id": "T_-7W2Z56C2K"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 4. TREINAMENTO DO MODELO (LightGBM)\n",
        "# ==============================================================================\n",
        "# LightGBM é uma excelente escolha para este tipo de problema.\n",
        "# Vamos treiná-lo com todos os dados de treino disponíveis.\n",
        "\n",
        "print(\"\\nIniciando o treinamento do modelo LightGBM...\")\n",
        "\n",
        "# Configuração dos parâmetros do LightGBM\n",
        "# Estes são parâmetros iniciais sólidos. Para melhores resultados,\n",
        "# eles podem ser otimizados (tuning) usando técnicas como GridSearch ou Optuna.\n",
        "lgb_params = {\n",
        "    'objective': 'multiclass',  # Nosso problema é de classificação com múltiplas classes\n",
        "    'metric': 'multi_logloss', # Métrica de avaliação durante o treino\n",
        "    'num_class': len(fertilizer_classes), # Número de classes que o modelo deve prever\n",
        "    'n_estimators': 2000,       # Número de árvores. Um valor alto, mas usaremos early stopping.\n",
        "    'learning_rate': 0.02,      # Taxa de aprendizado, controla o passo de cada iteração.\n",
        "    'feature_fraction': 0.8,    # Usa 80% das features em cada árvore\n",
        "    'bagging_fraction': 0.8,    # Usa 80% dos dados em cada árvore\n",
        "    'bagging_freq': 1,\n",
        "    'lambda_l1': 0.1,           # Regularização L1\n",
        "    'lambda_l2': 0.1,           # Regularização L2\n",
        "    'num_leaves': 31,           # Número de folhas por árvore\n",
        "    'verbose': -1,              # Suprime mensagens de log do LightGBM\n",
        "    'n_jobs': -1,               # Usa todos os cores de CPU disponíveis\n",
        "    'seed': 42,                 # Semente para reprodutibilidade\n",
        "    'boosting_type': 'gbdt',\n",
        "}\n",
        "\n",
        "# Criando o classificador\n",
        "model = lgb.LGBMClassifier(**lgb_params)\n",
        "\n",
        "# Treinando o modelo\n",
        "# Aqui, não estamos usando um conjunto de validação separado porque vamos treinar\n",
        "# com todos os dados disponíveis para maximizar a performance na submissão.\n",
        "# Em um projeto real, usaríamos validação cruzada para ter uma estimativa mais\n",
        "# robusta da performance do modelo.\n",
        "model.fit(X, y)\n",
        "\n",
        "print(\"Modelo treinado com sucesso!\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# 5. PREDIÇÃO E GERAÇÃO DO ARQUIVO DE SUBMISSÃO\n",
        "# ==============================================================================\n",
        "# Agora, usamos nosso modelo treinado para prever no conjunto de teste.\n",
        "# A métrica é MAP@3, então precisamos das 3 predições mais prováveis.\n",
        "\n",
        "print(\"\\nIniciando predições no conjunto de teste...\")\n",
        "\n",
        "# `predict_proba` retorna a probabilidade para cada uma das classes\n",
        "probabilities = model.predict_proba(X_test)\n",
        "\n",
        "# `argsort` nos dá os índices das classes, ordenados da menor para a maior probabilidade.\n",
        "# Usamos [:, ::-1] para inverter a ordem (maior para menor).\n",
        "# Pegamos os 3 primeiros com [:, :3].\n",
        "top_3_preds_indices = np.argsort(probabilities, axis=1)[:, ::-1][:, :3]\n",
        "\n",
        "# Agora, convertemos esses índices de volta para os nomes dos fertilizantes\n",
        "top_3_preds_labels = target_encoder.inverse_transform(top_3_preds_indices.flatten()).reshape(top_3_preds_indices.shape)\n",
        "\n",
        "# Formatando para o arquivo de submissão\n",
        "# A competição exige que as 3 predições estejam na mesma célula, separadas por espaço.\n",
        "predictions_formatted = [' '.join(preds) for preds in top_3_preds_labels]\n",
        "\n",
        "print(\"Predições formatadas com sucesso.\")\n",
        "\n",
        "\n",
        "# --- 5.1. Criação do arquivo de submissão ---\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': test_ids,\n",
        "    'Fertilizer Name': predictions_formatted\n",
        "})\n",
        "\n",
        "# Salvando o arquivo\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "\n",
        "print(\"\\nArquivo de submissão 'submission.csv' criado com sucesso!\")\n",
        "print(\"Primeiras 5 linhas da submissão:\")\n",
        "print(submission_df.head())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-27T02:33:30.208041Z",
          "iopub.execute_input": "2025-06-27T02:33:30.208387Z"
        },
        "id": "PFAGzGlt6C2K"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}