{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 86518,
          "databundleVersionId": 9809560,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31040,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Fine Tune - Francisco",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "mPsZi5I22Frm"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "llm_classification_finetuning_path = kagglehub.competition_download('llm-classification-finetuning')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "Qc3jIkN52Fro"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-26T20:18:59.245357Z",
          "iopub.execute_input": "2025-06-26T20:18:59.245691Z",
          "iopub.status.idle": "2025-06-26T20:18:59.252312Z",
          "shell.execute_reply.started": "2025-06-26T20:18:59.245668Z",
          "shell.execute_reply": "2025-06-26T20:18:59.251524Z"
        },
        "id": "OaJ145bF2Frp",
        "outputId": "253e3130-b92b-472a-c9de-f575de7b7400"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "/kaggle/input/llm-classification-finetuning/sample_submission.csv\n/kaggle/input/llm-classification-finetuning/train.csv\n/kaggle/input/llm-classification-finetuning/test.csv\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Caminhos dos arquivos dentro do ambiente Kaggle\n",
        "train_csv_path = '/kaggle/input/llm-classification-finetuning/train.csv'\n",
        "test_csv_path = '/kaggle/input/llm-classification-finetuning/test.csv'\n",
        "sample_submission_path = '/kaggle/input/llm-classification-finetuning/sample_submission.csv'\n",
        "\n",
        "# Carregar os arquivos CSV em DataFrames do pandas\n",
        "print(\"Carregando os dados...\")\n",
        "train_df = pd.read_csv(train_csv_path)\n",
        "test_df = pd.read_csv(test_csv_path)\n",
        "sample_submission_df = pd.read_csv(sample_submission_path)\n",
        "print(\"Dados carregados com sucesso!\")\n",
        "\n",
        "# É uma boa prática verificar se os dados foram carregados corretamente\n",
        "print(\"\\nInformações do DataFrame de Treino:\")\n",
        "train_df.info()\n",
        "\n",
        "print(\"\\nPrimeiras 5 linhas do DataFrame de Teste:\")\n",
        "print(test_df.head())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-26T20:18:59.253693Z",
          "iopub.execute_input": "2025-06-26T20:18:59.254019Z",
          "iopub.status.idle": "2025-06-26T20:19:01.001259Z",
          "shell.execute_reply.started": "2025-06-26T20:18:59.253997Z",
          "shell.execute_reply": "2025-06-26T20:19:01.000684Z"
        },
        "id": "TUHbbHZS2Frq",
        "outputId": "0b747ec9-3e91-4342-ce1f-5fd0d8e1b1e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Carregando os dados...\nDados carregados com sucesso!\n\nInformações do DataFrame de Treino:\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 57477 entries, 0 to 57476\nData columns (total 9 columns):\n #   Column          Non-Null Count  Dtype \n---  ------          --------------  ----- \n 0   id              57477 non-null  int64 \n 1   model_a         57477 non-null  object\n 2   model_b         57477 non-null  object\n 3   prompt          57477 non-null  object\n 4   response_a      57477 non-null  object\n 5   response_b      57477 non-null  object\n 6   winner_model_a  57477 non-null  int64 \n 7   winner_model_b  57477 non-null  int64 \n 8   winner_tie      57477 non-null  int64 \ndtypes: int64(4), object(5)\nmemory usage: 3.9+ MB\n\nPrimeiras 5 linhas do DataFrame de Teste:\n        id                                             prompt  \\\n0   136060  [\"I have three oranges today, I ate an orange ...   \n1   211333  [\"You are a mediator in a heated political deb...   \n2  1233961  [\"How to initialize the classification head wh...   \n\n                                          response_a  \\\n0                    [\"You have two oranges today.\"]   \n1  [\"Thank you for sharing the details of the sit...   \n2  [\"When you want to initialize the classificati...   \n\n                                          response_b  \n0  [\"You still have three oranges. Eating an oran...  \n1  [\"Mr Reddy and Ms Blue both have valid points ...  \n2  [\"To initialize the classification head when p...  \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Comprimento dos textos (pode indicar verbosidade)\n",
        "train_df['prompt_len'] = train_df['prompt'].str.len()\n",
        "train_df['response_a_len'] = train_df['response_a'].str.len()\n",
        "train_df['response_b_len'] = train_df['response_b'].str.len()\n",
        "\n",
        "# Diferença de comprimento (uma feature de comparação direta)\n",
        "train_df['len_diff'] = train_df['response_a_len'] - train_df['response_b_len']\n",
        "\n",
        "# Repita o mesmo para o test_df\n",
        "test_df['prompt_len'] = test_df['prompt'].str.len()\n",
        "test_df['response_a_len'] = test_df['response_a'].str.len()\n",
        "test_df['response_b_len'] = test_df['response_b'].str.len()\n",
        "test_df['len_diff'] = test_df['response_a_len'] - test_df['response_b_len']"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-26T20:24:42.752318Z",
          "iopub.execute_input": "2025-06-26T20:24:42.752546Z",
          "iopub.status.idle": "2025-06-26T20:24:42.816565Z",
          "shell.execute_reply.started": "2025-06-26T20:24:42.752532Z",
          "shell.execute_reply": "2025-06-26T20:24:42.816125Z"
        },
        "id": "TXM-7ywI2Frq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import log_loss\n",
        "import lightgbm as lgb\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "import numpy as np"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-26T20:24:58.221996Z",
          "iopub.execute_input": "2025-06-26T20:24:58.22223Z",
          "iopub.status.idle": "2025-06-26T20:25:02.16523Z",
          "shell.execute_reply.started": "2025-06-26T20:24:58.222215Z",
          "shell.execute_reply": "2025-06-26T20:25:02.164687Z"
        },
        "id": "bSNCDvmg2Frr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapear as colunas de vencedor para um único alvo\n",
        "target_map = {'winner_model_a': 0, 'winner_model_b': 1, 'winner_tie': 2}\n",
        "train_df['target'] = np.argmax(train_df[['winner_model_a', 'winner_model_b', 'winner_tie']].values, axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-26T20:25:09.169382Z",
          "iopub.execute_input": "2025-06-26T20:25:09.169963Z",
          "iopub.status.idle": "2025-06-26T20:25:09.176876Z",
          "shell.execute_reply.started": "2025-06-26T20:25:09.169943Z",
          "shell.execute_reply": "2025-06-26T20:25:09.1761Z"
        },
        "id": "F9dbE8_72Frr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar os vetorizadores\n",
        "# max_features limita o número de palavras (features) para controlar o uso de memória\n",
        "# ngram_range=(1, 2) considera palavras individuais e pares de palavras (bigramas)\n",
        "prompt_vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
        "response_a_vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 3))\n",
        "response_b_vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 3))\n",
        "\n",
        "# Treinar os vetorizadores nos dados de treino\n",
        "print(\"Treinando vetorizadores...\")\n",
        "X_prompt = prompt_vectorizer.fit_transform(train_df['prompt'])\n",
        "X_response_a = response_a_vectorizer.fit_transform(train_df['response_a'])\n",
        "X_response_b = response_b_vectorizer.fit_transform(train_df['response_b'])\n",
        "print(\"Vetorizadores treinados.\")\n",
        "\n",
        "# Aplicar os mesmos vetorizadores (já treinados) nos dados de teste\n",
        "X_test_prompt = prompt_vectorizer.transform(test_df['prompt'])\n",
        "X_test_response_a = response_a_vectorizer.transform(test_df['response_a'])\n",
        "X_test_response_b = response_b_vectorizer.transform(test_df['response_b'])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-26T20:25:26.313307Z",
          "iopub.execute_input": "2025-06-26T20:25:26.314022Z",
          "iopub.status.idle": "2025-06-26T20:27:49.072374Z",
          "shell.execute_reply.started": "2025-06-26T20:25:26.314004Z",
          "shell.execute_reply": "2025-06-26T20:27:49.071544Z"
        },
        "id": "CRww_omf2Frs",
        "outputId": "401f17d9-1fac-44d2-9317-58ff88e6b54a"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Treinando vetorizadores...\nVetorizadores treinados.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Extrair as features de comprimento\n",
        "meta_features_train = train_df[['prompt_len', 'response_a_len', 'response_b_len', 'len_diff']].values\n",
        "meta_features_test = test_df[['prompt_len', 'response_a_len', 'response_b_len', 'len_diff']].values\n",
        "\n",
        "# Combinar tudo usando hstack (horizontal stack)\n",
        "X_train_final = hstack([\n",
        "    X_prompt,\n",
        "    X_response_a,\n",
        "    X_response_b,\n",
        "    csr_matrix(meta_features_train)\n",
        "])\n",
        "\n",
        "X_test_final = hstack([\n",
        "    X_test_prompt,\n",
        "    X_test_response_a,\n",
        "    X_test_response_b,\n",
        "    csr_matrix(meta_features_test)\n",
        "])\n",
        "\n",
        "print(f\"Shape final da matriz de treino: {X_train_final.shape}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-26T20:27:49.073243Z",
          "iopub.execute_input": "2025-06-26T20:27:49.073406Z",
          "iopub.status.idle": "2025-06-26T20:27:49.171362Z",
          "shell.execute_reply.started": "2025-06-26T20:27:49.073393Z",
          "shell.execute_reply": "2025-06-26T20:27:49.170766Z"
        },
        "id": "ZQvzTIq32Frs",
        "outputId": "84346424-d3fc-455e-cf0e-4261d449a925"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Shape final da matriz de treino: (57477, 25004)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Parâmetros para o LightGBM (pode ser otimizado)\n",
        "params = {\n",
        "    'objective': 'multiclass',\n",
        "    'num_class': 3,\n",
        "    'metric': 'multi_logloss',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'n_estimators': 2000, # Aumentar para mais performance, mas demora mais\n",
        "    'learning_rate': 0.02,\n",
        "    'num_leaves': 31,\n",
        "    'max_depth': -1,\n",
        "    'seed': 42,\n",
        "    'n_jobs': -1,\n",
        "    'verbose': -1,\n",
        "}\n",
        "\n",
        "# Inicializar o modelo\n",
        "model = lgb.LGBMClassifier(**params)\n",
        "\n",
        "# Treinar o modelo\n",
        "print(\"Treinando o modelo LightGBM...\")\n",
        "# É uma boa prática usar callbacks para parar o treino se a performance não melhorar\n",
        "callbacks = [lgb.early_stopping(100, verbose=False)] # Para isso, precisa de um eval_set\n",
        "\n",
        "# Para um treino simples:\n",
        "model.fit(X_train_final, train_df['target'])\n",
        "print(\"Modelo treinado.\")\n",
        "\n",
        "# Fazer previsões no conjunto de teste\n",
        "print(\"Fazendo previsões...\")\n",
        "predictions_proba = model.predict_proba(X_test_final)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-26T20:27:49.171956Z",
          "iopub.execute_input": "2025-06-26T20:27:49.172145Z",
          "execution_failed": "2025-06-26T20:46:20.811Z"
        },
        "id": "JlfSk0DF2Frt",
        "outputId": "7ab72e07-08ef-4113-9f3e-4524eb0bbd0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Treinando o modelo LightGBM...\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar o DataFrame de submissão\n",
        "submission_df = pd.DataFrame(predictions_proba, columns=['winner_model_a', 'winner_model_b', 'winner_tie'])\n",
        "submission_df['id'] = test_df['id']\n",
        "submission_df = submission_df[['id', 'winner_model_a', 'winner_model_b', 'winner_tie']]\n",
        "\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "print(\"Arquivo submission.csv criado com sucesso!\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-06-26T20:46:20.813Z"
        },
        "id": "S8cPURSG2Frt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df = pd.DataFrame(\n",
        "    predictions_proba,\n",
        "    columns=['winner_model_a', 'winner_model_b', 'winner_tie']\n",
        ")\n",
        "submission_df['id'] = test_df['id']\n",
        "submission_df = submission_df[['id', 'winner_model_a', 'winner_model_b', 'winner_tie']]\n",
        "submission_df.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-06-26T20:46:20.813Z"
        },
        "id": "zpzKBEa-2Frt"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}